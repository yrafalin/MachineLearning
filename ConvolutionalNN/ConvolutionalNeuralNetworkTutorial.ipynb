{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "0. If you haven't already, follow [the setup instructions here](https://jennselby.github.io/MachineLearningCourseNotes/#setting-up-python3) to get all necessary software installed.\n",
    "0. Read through the code in the following sections:\n",
    "    * [First Model](#First-Model)\n",
    "    * [Create Images](#Create-Images)\n",
    "    * [Run Images Through Model](#Run-Images-Through-Model)\n",
    "0. Answer the [Model 1 Questions](#Model-1-Questions)\n",
    "0. Read through the code for the [Second Model](#Second-Model)\n",
    "0. Complete [Exercise #1](#Exercise-#1)\n",
    "0. Optionally, complete [Exercise #2](#Exercise-#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll want to import the keras modules we'll be using for our neural network and the numpy and matplotlib modules that we'll be using for displaying our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "import numpy\n",
    "from matplotlib.pyplot import imshow\n",
    "# tell matplotlib to display images within this notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model\n",
    "\n",
    "Next, let's set up the structure of our model. We'll start with a really simple model, with just one convolutional layer that has just one filter. We are going to be using 9x9-pixel grayscale images, so we set the input shape accordingly. If we were using color images with red-green-blue channels, the last dimension would be size three (one for each color) instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "image_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Conv2D(filters=1,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=1,\n",
    "                  input_shape=(image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally at this point, we would compile and train (aka fit) our model, but instead we're going to set the weights manually and then see the output we get on some test images.\n",
    "\n",
    "First, let's take a look at what the randomly generated weights look like, to understand the format that we'll need to use to set the new weights. By changing the parameters of the model above and looking at how it affects the weight structure, we can understand what each weight is connected to (try it!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.1515378 ]],\n",
       " \n",
       "         [[-0.5103589 ]],\n",
       " \n",
       "         [[ 0.39846092]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0263288 ]],\n",
       " \n",
       "         [[ 0.20211202]],\n",
       " \n",
       "         [[-0.22504869]]],\n",
       " \n",
       " \n",
       "        [[[-0.0561685 ]],\n",
       " \n",
       "         [[-0.24760145]],\n",
       " \n",
       "         [[ 0.08119869]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model0.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we change the weights so that the filter will capture a certain pattern. We'll explore more about what this means below, but feel free to start generating some guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1.]],\n",
       " \n",
       "         [[ 1.]],\n",
       " \n",
       "         [[ 1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "y = 0\n",
    "for x in range(kernel_size):\n",
    "    weights[layer_num][y][x][0][filter_num] = 1\n",
    "for y in range(1,kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        weights[layer_num][y][x][0][filter_num] = -1\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save those weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Images\n",
    "\n",
    "Now, let's create some 9x9 images that we will run through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13cfcf820>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image0 = numpy.array([\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13f234310>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = numpy.array([\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image1, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Images Through Model\n",
    "\n",
    "The images need to be in a slightly different format for Keras than they do for the imshow command. Right now, they are 9x9 arrays, and we need them to be 9x9x1 -- three dimensional instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in [image0, image1]: # You may find it easier to take one of these out, to look at them one at a time\n",
    "    images.append(numpy.resize(image, (image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we give these images to our model and take a look at what the filter has found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]],\n",
       "\n",
       "        [[-256.],\n",
       "         [-383.],\n",
       "         [-511.],\n",
       "         [-383.],\n",
       "         [-256.],\n",
       "         [-383.],\n",
       "         [-511.]]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.predict(numpy.array([images[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]],\n",
       "\n",
       "        [[  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.]],\n",
       "\n",
       "        [[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.predict(numpy.array([images[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 Questions\n",
    "\n",
    "### Answer these before going on to the second model!\n",
    "\n",
    "1. There are a lot of numbers in the output above: 2 arrays of 7 arrays of 7 arrays of a single element. Why are they in groups of seven?\n",
    "\n",
    "2. When we created the model, we asked it to have one filter. In which image do we get the highest absolute values in the filter outputs? How does this relate to the pattern of weights that was set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The kernel needs a margin of 1 pixel when it is applied. Since the image is 9x9, it can only begin to be applied in the second row and in the second column, and cannot be applied in the last row or column either, so it has 7 rows, and 7 columns to work with, resulting in a 7 by 7 array.\n",
    "2. We get the highest absolute values in second and sevenths rows in the second image, where the kernel aligns with rows of 0, 128, and 256 pixel values. In this case, the positive weights correspond to the 0 row, adding nothing, while the -1 weights subtract the larger pixel values, resulting in the highest absolute value outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "\n",
    "Let's move to a slightly more complex model. Now, there are two convolutional layers, the first with two filters and the second with one filter. One other difference is that we're going to be taking strides so that we only examine each pixel once, instead of looking at overlapping groups. This makes it a little simpler to understand the manual weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(filters=2,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(3,3),\n",
    "                  input_shape=(image_size, image_size, 1)))\n",
    "model1.add(Conv2D(filters=1, kernel_size=kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a different model structure, we will have a different number of weights to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.27535143, -0.29803675]],\n",
       " \n",
       "         [[-0.24197416, -0.45651117]],\n",
       " \n",
       "         [[-0.4074138 , -0.00601262]]],\n",
       " \n",
       " \n",
       "        [[[ 0.12398818,  0.46588376]],\n",
       " \n",
       "         [[-0.31847373,  0.3548576 ]],\n",
       " \n",
       "         [[-0.16877487,  0.21706513]]],\n",
       " \n",
       " \n",
       "        [[[ 0.36246422,  0.13494161]],\n",
       " \n",
       "         [[ 0.25647596, -0.39672458]],\n",
       " \n",
       "         [[ 0.21139249,  0.46775177]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 0.21775779],\n",
       "          [ 0.00582221]],\n",
       " \n",
       "         [[ 0.39069423],\n",
       "          [-0.44069555]],\n",
       " \n",
       "         [[-0.33965975],\n",
       "          [ 0.23972073]]],\n",
       " \n",
       " \n",
       "        [[[-0.05902806],\n",
       "          [ 0.25139204]],\n",
       " \n",
       "         [[ 0.2080926 ],\n",
       "          [ 0.156149  ]],\n",
       " \n",
       "         [[-0.25924167],\n",
       "          [-0.01469305]]],\n",
       " \n",
       " \n",
       "        [[[ 0.22782835],\n",
       "          [-0.01790321]],\n",
       " \n",
       "         [[-0.10836798],\n",
       "          [ 0.44591692]],\n",
       " \n",
       "         [[-0.10198516],\n",
       "          [-0.36859554]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we manually set the weights to match some specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1\n",
    "\n",
    "filter_num = 1\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1., -1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[-1.,  1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1.]],\n",
       " \n",
       "         [[ 1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[ 1., -1.]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 1.  ],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [ 1.  ]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [-0.25]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer 1 is for setting the biases of the first layer.\n",
    "# They are zero by default, so leave them that way and\n",
    "# move on to layer 2, which contains the weights for the\n",
    "# filters of the second layer.\n",
    "layer_num = 2\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        input_filter_num = 0\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "        input_filter_num = 1\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, run our test images through the model to see what the filters output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(images):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        resized_images.append(numpy.resize(image, (image_size, image_size, 1)))\n",
    "    return model1.predict(numpy.array(resized_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1150.]]],\n",
       "\n",
       "\n",
       "       [[[-1150.]]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image0, image1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #1\n",
    "\n",
    "Note above that neither image0 nor image1 gets a positive output. Create some images that do get positive ouputs from this model. The code below might help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13cf55e50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_black = numpy.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_black, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13fcbb2b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_white = numpy.array([\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_white, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14019cf40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_crossed = numpy.array([\n",
    "    [255, 0, 0, 0, 0, 0, 0, 0, 255],\n",
    "    [0, 255, 0, 0, 0, 0, 0, 255, 0],\n",
    "    [0, 0, 255, 0, 0, 0, 255, 0, 0],\n",
    "    [0, 0, 0, 255, 0, 255, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 255, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 255, 0, 255, 0, 0, 0],\n",
    "    [0, 0, 255, 0, 0, 0, 255, 0, 0],\n",
    "    [0, 255, 0, 0, 0, 0, 0, 255, 0],\n",
    "    [255, 0, 0, 0, 0, 0, 0, 0, 255],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_crossed, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[    0.]]],\n",
       "\n",
       "\n",
       "       [[[-2295.]]],\n",
       "\n",
       "\n",
       "       [[[ 3825.]]]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image_black, image_white, image_crossed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #2\n",
    "\n",
    "### Optional\n",
    "\n",
    "Add additional filters to the model or create a new model with your own filters. Create images that get positive weights for different patterns of filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Horizontal Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(filters=2,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(3,3),\n",
    "                  input_shape=(image_size, image_size, 1)))\n",
    "model2.add(Conv2D(filters=1, kernel_size=kernel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.04519042, -0.22506182]],\n",
       " \n",
       "         [[ 0.25961438, -0.21785527]],\n",
       " \n",
       "         [[ 0.1648641 , -0.1376597 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0803639 , -0.4041693 ]],\n",
       " \n",
       "         [[-0.2549383 ,  0.4337894 ]],\n",
       " \n",
       "         [[-0.04340866,  0.34009328]]],\n",
       " \n",
       " \n",
       "        [[[ 0.34280697,  0.16212884]],\n",
       " \n",
       "         [[-0.31883395, -0.43433002]],\n",
       " \n",
       "         [[-0.04793513,  0.44109073]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[-0.39593178],\n",
       "          [-0.3324179 ]],\n",
       " \n",
       "         [[ 0.10357854],\n",
       "          [ 0.0806804 ]],\n",
       " \n",
       "         [[ 0.05672911],\n",
       "          [ 0.3675901 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.4037784 ],\n",
       "          [-0.43896225]],\n",
       " \n",
       "         [[ 0.07876369],\n",
       "          [-0.07335508]],\n",
       " \n",
       "         [[ 0.15535489],\n",
       "          [-0.2531958 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.4330754 ],\n",
       "          [-0.33029014]],\n",
       " \n",
       "         [[-0.04321963],\n",
       "          [-0.43089375]],\n",
       " \n",
       "         [[ 0.29783055],\n",
       "          [-0.03226584]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model2.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if y == 1:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -0.5\n",
    "\n",
    "filter_num = 1\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if x == 1:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.5, -0.5]],\n",
       " \n",
       "         [[-0.5,  1. ]],\n",
       " \n",
       "         [[-0.5, -0.5]]],\n",
       " \n",
       " \n",
       "        [[[ 1. , -0.5]],\n",
       " \n",
       "         [[ 1. ,  1. ]],\n",
       " \n",
       "         [[ 1. , -0.5]]],\n",
       " \n",
       " \n",
       "        [[[-0.5, -0.5]],\n",
       " \n",
       "         [[-0.5,  1. ]],\n",
       " \n",
       "         [[-0.5, -0.5]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 1.  ],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [-0.25]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [ 1.  ]]],\n",
       " \n",
       " \n",
       "        [[[ 1.  ],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [-0.25]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_num = 2\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        input_filter_num = 0\n",
    "        if y in [0,2] and x in [0,2]:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "        input_filter_num = 1\n",
    "        if (y == 1 and x in [0,2]) or (x == 1 and y in [0,2]):\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images2(images):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        resized_images.append(numpy.resize(image, (image_size, image_size, 1)))\n",
    "    return model2.predict(numpy.array(resized_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x141654070>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_random = numpy.random.randint(2, size=(9,9))\n",
    "image_random = numpy.where(image_random == 1, 255, 0)\n",
    "image_random = image_random.astype(numpy.uint8)\n",
    "imshow(image_random, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14110fbb0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_bars = numpy.array([\n",
    "    [0, 0, 0, 0, 255, 0, 0, 0, 0],\n",
    "    [255, 255, 255, 0, 255, 0, 255, 255, 255],\n",
    "    [0, 0, 0, 0, 255, 0, 0, 0, 0],\n",
    "    [0, 255, 0, 0, 0, 0, 0, 255, 0],\n",
    "    [0, 255, 0, 0, 0, 0, 0, 255, 0],\n",
    "    [0, 255, 0, 0, 0, 0, 0, 255, 0],\n",
    "    [0, 0, 0, 0, 255, 0, 0, 0, 0],\n",
    "    [255, 255, 255, 0, 255, 0, 255, 255, 255],\n",
    "    [0, 0, 0, 0, 255, 0, 0, 0, 0],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_bars, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[   0.  ]]],\n",
       "\n",
       "\n",
       "       [[[   0.  ]]],\n",
       "\n",
       "\n",
       "       [[[ 127.5 ]]],\n",
       "\n",
       "\n",
       "       [[[ 318.75]]],\n",
       "\n",
       "\n",
       "       [[[6120.  ]]]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images2([image_black, image_white, image_crossed, image_random, image_bars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very cool"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
